{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48ef1987-f9f7-4b88-9b0a-66b4030e4c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in c:\\users\\ryand\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.14.4)\n",
      "Requirement already satisfied: transformers[sentencepiece] in c:\\users\\ryand\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.33.3)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in c:\\users\\ryand\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (13.0.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\ryand\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (1.4.3)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\ryand\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (3.8.5)\n",
      "Requirement already satisfied: xxhash in c:\\users\\ryand\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (3.3.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\ryand\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in c:\\users\\ryand\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (0.3.7)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\ryand\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (2.28.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in c:\\users\\ryand\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (0.16.4)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\ryand\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (0.70.15)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\ryand\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (1.24.1)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\ryand\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (4.62.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\ryand\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (21.3)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in c:\\users\\ryand\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (2023.6.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\ryand\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers[sentencepiece]) (0.3.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\ryand\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers[sentencepiece]) (3.12.2)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\ryand\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers[sentencepiece]) (0.13.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\ryand\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers[sentencepiece]) (2022.1.18)\n",
      "Requirement already satisfied: protobuf in c:\\users\\ryand\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers[sentencepiece]) (4.24.2)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in c:\\users\\ryand\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers[sentencepiece]) (0.1.99)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\ryand\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp->datasets) (2.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\ryand\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\ryand\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\ryand\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\ryand\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\ryand\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\ryand\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp->datasets) (1.9.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\ryand\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.5.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\ryand\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from packaging->datasets) (3.0.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ryand\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.19.0->datasets) (2022.6.15)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\ryand\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.19.0->datasets) (1.26.10)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ryand\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.19.0->datasets) (3.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\ryand\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm>=4.62.1->datasets) (0.4.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\ryand\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ryand\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas->datasets) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ryand\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
      "\n",
      "[notice] A new release of pip available: 22.1.2 -> 23.2.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -upyterlab (c:\\users\\ryand\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -upyterlab (c:\\users\\ryand\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -upyterlab (c:\\users\\ryand\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -upyterlab (c:\\users\\ryand\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -upyterlab (c:\\users\\ryand\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -upyterlab (c:\\users\\ryand\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "! pip install datasets transformers[sentencepiece]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3372be6b-41f6-49f8-ae39-b87da4aaadcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
    "\n",
    "raw_datasets = load_dataset(\"glue\", \"mrpc\")\n",
    "checkpoint = \"bert-base-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"sentence1\"], examples[\"sentence2\"], truncation=True)\n",
    "\n",
    "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n",
    "data_collator = DataCollatorWithPadding(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4dfe2ee8-1db6-4c6e-af82-58fdc62c6efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9ac0277-40ad-4397-98e5-7a316c14b737",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments # Used to fine tune the training for a model\n",
    "\n",
    "training_args = TrainingArguments(\"test-trainer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04caa28e-190d-41b9-92ad-2bcc3399c69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    \"test-trainer\",\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=5,\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01, # regularization technique. prevents overfitting and keeps the weights small to avoid exploding gradient\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9922445f-a3d0-4991-8ce2-549b6cbb3dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1150' max='1150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1150/1150 01:31, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.472000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.188700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1150, training_loss=0.3009665580417799, metrics={'train_runtime': 92.7948, 'train_samples_per_second': 197.64, 'train_steps_per_second': 12.393, 'total_flos': 743901286817760.0, 'train_loss': 0.3009665580417799, 'epoch': 5.0})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    training_args, # Defines the Training Parameters to update the NN (Neural Network)\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "trainer.train() # Note we are not seeing accuracy or f1 because we do not have a validation set being used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3beb36d-71b9-4473-a693-1170bacce8d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(408, 2) (408,)\n",
      "[[-3.7294462   3.5800664 ]\n",
      " [ 2.2895823  -2.762918  ]\n",
      " [ 2.3971639  -2.7603602 ]\n",
      " [-3.4544723   3.3419147 ]\n",
      " [ 2.3377914  -2.8346415 ]\n",
      " [-3.6039479   3.4062026 ]\n",
      " [-3.4565754   3.239911  ]\n",
      " [-3.5567927   3.4100459 ]\n",
      " [-3.5135212   3.4019623 ]\n",
      " [-3.7371356   3.6474023 ]\n",
      " [-3.7279482   3.6426263 ]\n",
      " [ 2.3157458  -2.623676  ]\n",
      " [ 1.1354722  -1.4750443 ]\n",
      " [-3.2140887   3.0884614 ]\n",
      " [-3.6602576   3.4905145 ]\n",
      " [ 1.3785053  -1.7331703 ]\n",
      " [-3.5494585   3.4154987 ]\n",
      " [ 1.0237976  -1.3907193 ]\n",
      " [-3.7088525   3.55927   ]\n",
      " [ 2.4243627  -2.7525692 ]\n",
      " [ 1.9734621  -2.2701147 ]\n",
      " [-3.3525794   3.202755  ]\n",
      " [ 2.067732   -2.6602693 ]\n",
      " [-3.7118523   3.521712  ]\n",
      " [-3.3663173   3.1977322 ]\n",
      " [-2.5777876   2.4168923 ]\n",
      " [-2.499741    2.2923636 ]\n",
      " [-3.7272248   3.5977354 ]\n",
      " [-3.128612    2.8779225 ]\n",
      " [-3.5742106   3.4678948 ]\n",
      " [ 1.72036    -2.2012115 ]\n",
      " [-3.649586    3.4632852 ]\n",
      " [-3.4231124   3.2625098 ]\n",
      " [-3.3250952   3.1777716 ]\n",
      " [-3.6424305   3.5893795 ]\n",
      " [-3.3338046   3.2462592 ]\n",
      " [ 1.516792   -1.9352869 ]\n",
      " [ 2.549008   -2.9514332 ]\n",
      " [ 0.74987257 -1.0874226 ]\n",
      " [-3.6936347   3.53454   ]\n",
      " [ 2.2293446  -2.8797348 ]\n",
      " [-3.5849757   3.3647559 ]\n",
      " [ 2.071249   -2.551168  ]\n",
      " [ 2.0884829  -2.6494093 ]\n",
      " [ 1.1839026  -1.563619  ]\n",
      " [-3.5924249   3.46111   ]\n",
      " [-3.6028938   3.426619  ]\n",
      " [ 2.4056547  -2.7236502 ]\n",
      " [-3.4694066   3.1765518 ]\n",
      " [-3.2337635   3.0761633 ]\n",
      " [-2.608815    2.5718482 ]\n",
      " [-3.4583166   3.3002758 ]\n",
      " [-3.5021174   3.3596575 ]\n",
      " [-3.6505413   3.4368727 ]\n",
      " [-3.6148062   3.5156476 ]\n",
      " [-3.610697    3.4950585 ]\n",
      " [-0.7024028   0.3246531 ]\n",
      " [-3.6144242   3.511776  ]\n",
      " [-3.6808927   3.5613327 ]\n",
      " [-3.5975008   3.4330878 ]\n",
      " [-3.573343    3.4100153 ]\n",
      " [-2.160757    1.8253818 ]\n",
      " [-3.6122158   3.5304425 ]\n",
      " [-3.2092748   3.0583932 ]\n",
      " [-3.4800985   3.3783402 ]\n",
      " [ 1.6203682  -2.0051343 ]\n",
      " [-3.6015275   3.4002445 ]\n",
      " [-3.6257374   3.4690127 ]\n",
      " [ 2.2335107  -2.6431456 ]\n",
      " [-3.712777    3.5452068 ]\n",
      " [-3.5816588   3.4203756 ]\n",
      " [-1.9163517   1.6035253 ]\n",
      " [-3.517631    3.3708417 ]\n",
      " [-3.5560608   3.3963134 ]\n",
      " [-3.4901462   3.306315  ]\n",
      " [-3.286801    3.1289225 ]\n",
      " [-2.9048674   2.8958619 ]\n",
      " [-3.7682953   3.6221125 ]\n",
      " [-3.6902146   3.5491703 ]\n",
      " [-3.5057411   3.32692   ]\n",
      " [-2.6366994   2.350891  ]\n",
      " [-3.7077475   3.527596  ]\n",
      " [-3.6438832   3.4281998 ]\n",
      " [ 1.9817868  -2.3932936 ]\n",
      " [-3.420868    3.2590418 ]\n",
      " [-2.4000676   2.076428  ]\n",
      " [-3.2833846   3.1762292 ]\n",
      " [-2.3939233   2.371752  ]\n",
      " [-3.6675098   3.5519853 ]\n",
      " [-3.6481848   3.5068731 ]\n",
      " [ 1.0071672  -1.2651463 ]\n",
      " [-3.5189009   3.3890445 ]\n",
      " [-3.5941894   3.4653718 ]\n",
      " [-1.6939148   1.2306275 ]\n",
      " [-3.5860777   3.4692564 ]\n",
      " [-3.624642    3.4941893 ]\n",
      " [ 2.4436884  -2.8019364 ]\n",
      " [-3.390998    3.1927173 ]\n",
      " [-3.644231    3.5421317 ]\n",
      " [-3.3916674   3.2246225 ]\n",
      " [-3.664562    3.5522487 ]\n",
      " [-2.5959105   2.534216  ]\n",
      " [-3.5619757   3.44467   ]\n",
      " [-3.6788228   3.553883  ]\n",
      " [ 0.98980445 -1.4980838 ]\n",
      " [-3.4272344   3.1810317 ]\n",
      " [-3.3731694   3.104778  ]\n",
      " [ 2.2090433  -2.7662888 ]\n",
      " [ 2.3245978  -2.7063289 ]\n",
      " [-3.1265996   3.001505  ]\n",
      " [-2.8219757   2.6939366 ]\n",
      " [-3.6573243   3.5098624 ]\n",
      " [-3.4895403   3.35022   ]\n",
      " [-3.6645494   3.5405834 ]\n",
      " [-3.2640696   3.0523987 ]\n",
      " [ 2.3857229  -2.8064435 ]\n",
      " [-3.4262505   3.211507  ]\n",
      " [-3.689732    3.508881  ]\n",
      " [-3.5476594   3.3804464 ]\n",
      " [-3.7429795   3.5706182 ]\n",
      " [-3.4909751   3.2987318 ]\n",
      " [-2.972149    2.7278824 ]\n",
      " [ 2.0109167  -2.600726  ]\n",
      " [-3.51941     3.3401437 ]\n",
      " [-3.6526248   3.5342326 ]\n",
      " [-3.6918242   3.4375303 ]\n",
      " [-3.552476    3.438666  ]\n",
      " [ 2.347449   -2.8158224 ]\n",
      " [-3.6761067   3.5338502 ]\n",
      " [-3.6778817   3.5945215 ]\n",
      " [-3.39392     3.323279  ]\n",
      " [ 1.7125971  -2.2099133 ]\n",
      " [-3.563925    3.4344344 ]\n",
      " [ 1.4175166  -1.7853304 ]\n",
      " [-0.8468745   0.31759593]\n",
      " [-3.5267808   3.3864443 ]\n",
      " [ 2.1377919  -2.5741782 ]\n",
      " [ 2.1209846  -2.4834912 ]\n",
      " [-3.5716095   3.4954276 ]\n",
      " [-3.1251345   2.9475582 ]\n",
      " [-3.6859422   3.5435286 ]\n",
      " [-3.4731      3.3056629 ]\n",
      " [ 1.8688993  -2.2106357 ]\n",
      " [-3.5866394   3.3876767 ]\n",
      " [ 2.519909   -2.9159822 ]\n",
      " [-1.5880562   1.3513485 ]\n",
      " [-3.6437745   3.501719  ]\n",
      " [-1.3870468   1.1065062 ]\n",
      " [-2.6734784   2.5403733 ]\n",
      " [-3.4823427   3.3042116 ]\n",
      " [ 2.2618961  -2.5687795 ]\n",
      " [-3.2639756   3.1179397 ]\n",
      " [-2.4578135   2.3227906 ]\n",
      " [-3.5954494   3.4690342 ]\n",
      " [-3.40129     3.2623324 ]\n",
      " [-3.536535    3.421387  ]\n",
      " [-3.6487792   3.4639351 ]\n",
      " [-3.0638704   2.717914  ]\n",
      " [ 1.6085128  -2.0095716 ]\n",
      " [-3.4253693   3.2503924 ]\n",
      " [-3.3459804   3.2119532 ]\n",
      " [-3.392491    3.1662493 ]\n",
      " [-3.5510972   3.4199443 ]\n",
      " [-3.6885316   3.5637152 ]\n",
      " [-3.4972463   3.2782454 ]\n",
      " [-3.3567348   3.288991  ]\n",
      " [-3.3284104   3.204053  ]\n",
      " [ 2.32686    -2.6426978 ]\n",
      " [-3.427725    3.2540443 ]\n",
      " [ 2.3655276  -2.7793589 ]\n",
      " [-2.3963542   2.3121028 ]\n",
      " [-1.6787368   1.2531409 ]\n",
      " [-2.6559985   2.5112488 ]\n",
      " [-2.819126    2.4603484 ]\n",
      " [ 0.42282328 -1.0526978 ]\n",
      " [-3.6727464   3.5022411 ]\n",
      " [-3.580666    3.4133646 ]\n",
      " [ 1.345071   -1.8053871 ]\n",
      " [-3.6651366   3.570935  ]\n",
      " [-3.6134536   3.473907  ]\n",
      " [ 2.1588817  -2.5827081 ]\n",
      " [ 0.16755465 -0.5456265 ]\n",
      " [-3.6036153   3.4411845 ]\n",
      " [-3.614113    3.4316475 ]\n",
      " [-3.0003567   2.81645   ]\n",
      " [-3.6462471   3.4559386 ]\n",
      " [ 2.2975116  -2.635183  ]\n",
      " [-3.4074051   3.284985  ]\n",
      " [ 2.427357   -2.8577404 ]\n",
      " [-3.5585341   3.3714604 ]\n",
      " [-3.6225417   3.4344094 ]\n",
      " [ 2.4215868  -2.9024725 ]\n",
      " [ 2.4119282  -2.8906813 ]\n",
      " [-3.4560385   3.3636093 ]\n",
      " [-1.7051944   1.3759108 ]\n",
      " [-3.4723816   3.2986877 ]\n",
      " [-3.5844588   3.386461  ]\n",
      " [ 0.99713904 -1.4039626 ]\n",
      " [-3.5878432   3.27504   ]\n",
      " [-3.5615394   3.489705  ]\n",
      " [-3.4187047   3.3213565 ]\n",
      " [-3.5635533   3.4688487 ]\n",
      " [ 0.98926246 -1.3131527 ]\n",
      " [-2.6328995   2.3520038 ]\n",
      " [-3.5205526   3.3751354 ]\n",
      " [ 0.20793498 -0.60442734]\n",
      " [-3.3560727   3.2082047 ]\n",
      " [-3.4402235   3.2085714 ]\n",
      " [ 2.4097724  -2.8042088 ]\n",
      " [-2.5050611   2.2824378 ]\n",
      " [-1.7122327   1.4316782 ]\n",
      " [-3.5982902   3.5086875 ]\n",
      " [-0.28021222  0.12709746]\n",
      " [ 2.3525007  -2.7938833 ]\n",
      " [-3.63045     3.4210262 ]\n",
      " [-3.6041074   3.4220135 ]\n",
      " [-3.2478316   3.1837363 ]\n",
      " [-3.518499    3.3151999 ]\n",
      " [ 2.156148   -2.7741652 ]\n",
      " [-3.375637    3.279026  ]\n",
      " [-0.09141667 -0.45633063]\n",
      " [-3.3770988   3.253158  ]\n",
      " [-3.5208085   3.338543  ]\n",
      " [ 1.8020432  -2.1375837 ]\n",
      " [-3.3964527   3.2593179 ]\n",
      " [-3.6233454   3.5028546 ]\n",
      " [-3.721044    3.565466  ]\n",
      " [-3.4895039   3.253566  ]\n",
      " [-3.3743508   3.2059443 ]\n",
      " [-3.1200628   2.927168  ]\n",
      " [-3.6600275   3.54675   ]\n",
      " [-3.6502583   3.5173328 ]\n",
      " [ 0.28725392 -0.88821566]\n",
      " [ 1.8279009  -2.292933  ]\n",
      " [ 2.4136782  -2.7515993 ]\n",
      " [ 2.194258   -2.743038  ]\n",
      " [ 2.2855778  -2.749621  ]\n",
      " [ 2.5475025  -2.8361187 ]\n",
      " [-3.7128057   3.5934865 ]\n",
      " [-2.9687116   2.8734348 ]\n",
      " [-3.278413    3.1238296 ]\n",
      " [ 2.24679    -2.5961528 ]\n",
      " [-1.2712506   0.9809188 ]\n",
      " [-2.629151    2.3353193 ]\n",
      " [-3.699645    3.5848007 ]\n",
      " [-3.6471431   3.4632328 ]\n",
      " [-3.4504857   3.3530543 ]\n",
      " [-2.1501927   1.7094973 ]\n",
      " [-3.5326564   3.3205988 ]\n",
      " [-3.4103022   3.265328  ]\n",
      " [-3.5282204   3.3935356 ]\n",
      " [-2.7126975   2.4588156 ]\n",
      " [-0.37720576  0.08262608]\n",
      " [-3.2455318   3.0216784 ]\n",
      " [ 2.0885112  -2.552292  ]\n",
      " [ 2.202494   -2.6281557 ]\n",
      " [-3.5267751   3.3891745 ]\n",
      " [-3.673056    3.468457  ]\n",
      " [-3.6079261   3.484159  ]\n",
      " [ 0.14302737 -0.7413803 ]\n",
      " [-3.342243    3.1582408 ]\n",
      " [-3.4772062   3.3334126 ]\n",
      " [-3.3850648   3.187812  ]\n",
      " [-3.4194453   3.2144005 ]\n",
      " [-2.5252345   2.431037  ]\n",
      " [ 1.8323689  -2.1402636 ]\n",
      " [-2.5913825   2.3509638 ]\n",
      " [ 1.8630413  -2.3381457 ]\n",
      " [ 1.2880926  -1.8637581 ]\n",
      " [-3.60445     3.5255005 ]\n",
      " [ 2.2072065  -2.72539   ]\n",
      " [-3.6235745   3.5249298 ]\n",
      " [-3.5932035   3.4196181 ]\n",
      " [-3.4110885   3.2138097 ]\n",
      " [-3.6524286   3.5467849 ]\n",
      " [-3.6449676   3.516918  ]\n",
      " [-3.368487    3.268501  ]\n",
      " [-2.2110445   2.0449054 ]\n",
      " [-3.4592865   3.3243554 ]\n",
      " [ 2.371945   -2.7951355 ]\n",
      " [-2.1526957   2.1656628 ]\n",
      " [-2.9569032   2.7404397 ]\n",
      " [-2.5991054   2.3076844 ]\n",
      " [ 2.2858832  -2.6242077 ]\n",
      " [-1.9434015   1.651272  ]\n",
      " [-3.6389062   3.3896775 ]\n",
      " [-3.7423894   3.4911017 ]\n",
      " [-3.0330503   2.9460227 ]\n",
      " [-3.67196     3.4953609 ]\n",
      " [ 0.59293544 -1.0293894 ]\n",
      " [ 1.6988282  -2.070772  ]\n",
      " [ 1.977712   -2.3655121 ]\n",
      " [-3.6419442   3.5458703 ]\n",
      " [-3.4905522   3.3812358 ]\n",
      " [-3.7210262   3.543025  ]\n",
      " [ 2.0692832  -2.5165732 ]\n",
      " [ 2.339089   -2.7831104 ]\n",
      " [-3.1474996   2.9919105 ]\n",
      " [-3.5658896   3.407228  ]\n",
      " [-2.857571    2.8581336 ]\n",
      " [-3.6464882   3.5485249 ]\n",
      " [-3.5910954   3.4341555 ]\n",
      " [-3.4563398   3.2944474 ]\n",
      " [ 1.3360044  -1.7798053 ]\n",
      " [-3.627746    3.469921  ]\n",
      " [-3.6178136   3.467698  ]\n",
      " [ 2.433053   -2.7749596 ]\n",
      " [-3.6013575   3.4502761 ]\n",
      " [ 2.104155   -2.518238  ]\n",
      " [ 2.2098851  -2.5951705 ]\n",
      " [-1.8513376   1.5483509 ]\n",
      " [-3.595879    3.423476  ]\n",
      " [-3.0274832   2.705362  ]\n",
      " [ 2.3932323  -2.8098543 ]\n",
      " [-3.6976233   3.6225426 ]\n",
      " [ 2.2559798  -2.6134546 ]\n",
      " [-2.8048038   2.6045272 ]\n",
      " [-3.5979397   3.4396682 ]\n",
      " [ 1.847455   -2.225731  ]\n",
      " [ 2.1870422  -2.6758037 ]\n",
      " [ 1.8625298  -2.4793062 ]\n",
      " [ 2.3989787  -2.7869601 ]\n",
      " [ 1.0515865  -1.3860523 ]\n",
      " [-0.11545967 -0.21061794]\n",
      " [ 2.1330729  -2.5193899 ]\n",
      " [-3.6936274   3.6176686 ]\n",
      " [ 0.71710676 -0.9181698 ]\n",
      " [-3.636866    3.4832428 ]\n",
      " [-2.922089    2.8237205 ]\n",
      " [-2.48217     2.2251794 ]\n",
      " [-3.7261312   3.6287374 ]\n",
      " [-3.6877196   3.5617428 ]\n",
      " [-3.4273474   3.3197398 ]\n",
      " [-3.1493504   3.1025732 ]\n",
      " [-3.6381555   3.5046644 ]\n",
      " [-3.204732    3.1096444 ]\n",
      " [-3.71265     3.5011873 ]\n",
      " [-3.6993713   3.5759714 ]\n",
      " [ 2.1078098  -2.536836  ]\n",
      " [-3.3686476   3.2748134 ]\n",
      " [-3.446723    3.2473898 ]\n",
      " [-3.5822778   3.471392  ]\n",
      " [ 2.1006355  -2.6692455 ]\n",
      " [-2.1211224   1.8436636 ]\n",
      " [-3.5666      3.372271  ]\n",
      " [-3.688491    3.5517356 ]\n",
      " [-3.5335474   3.43948   ]\n",
      " [-3.5876758   3.4382567 ]\n",
      " [-2.1733177   2.0774064 ]\n",
      " [-3.625771    3.4696796 ]\n",
      " [ 2.2768223  -2.6561942 ]\n",
      " [-3.712218    3.6063855 ]\n",
      " [-2.699649    2.7270124 ]\n",
      " [-3.2653847   3.0564623 ]\n",
      " [-2.7938507   2.596023  ]\n",
      " [-3.0077305   2.8719702 ]\n",
      " [-3.3789709   3.2962394 ]\n",
      " [-3.1570988   3.0677974 ]\n",
      " [-3.4067137   3.291614  ]\n",
      " [-3.678813    3.5670063 ]\n",
      " [-2.9701955   2.9328227 ]\n",
      " [-2.4379134   2.160626  ]\n",
      " [-3.5851185   3.4125242 ]\n",
      " [-2.284952    2.1960776 ]\n",
      " [-3.626591    3.5107396 ]\n",
      " [-3.6500049   3.4926639 ]\n",
      " [-3.6786032   3.5044036 ]\n",
      " [-3.0882003   2.840107  ]\n",
      " [ 1.5145714  -2.028753  ]\n",
      " [ 1.6623915  -2.0409873 ]\n",
      " [-2.6487517   2.3361263 ]\n",
      " [-3.7608051   3.6053834 ]\n",
      " [-3.481186    3.159673  ]\n",
      " [-2.9702814   2.7500315 ]\n",
      " [ 2.3012807  -2.670727  ]\n",
      " [ 2.501825   -2.8382719 ]\n",
      " [-3.4359677   3.2869153 ]\n",
      " [ 2.3512762  -2.7143588 ]\n",
      " [-3.5357585   3.4314365 ]\n",
      " [-3.6898317   3.4597785 ]\n",
      " [-3.3392997   3.1780725 ]\n",
      " [-3.6363945   3.4970412 ]\n",
      " [-1.895174    1.7308916 ]\n",
      " [-3.6944501   3.599272  ]\n",
      " [-3.3637335   3.3045015 ]\n",
      " [-2.710018    2.4405823 ]\n",
      " [-2.8869522   2.7943242 ]\n",
      " [ 2.0191646  -2.3023827 ]\n",
      " [-3.5840364   3.518248  ]\n",
      " [-3.1510425   3.0233943 ]\n",
      " [-3.7189386   3.5868852 ]\n",
      " [-3.061745    2.849438  ]\n",
      " [-3.593       3.4699767 ]\n",
      " [-3.5881999   3.4425635 ]\n",
      " [-3.5274746   3.3118455 ]\n",
      " [ 1.5461776  -1.9081076 ]\n",
      " [-3.7162273   3.5605075 ]\n",
      " [-0.649469    0.55229783]\n",
      " [-2.8944373   2.6448696 ]\n",
      " [-3.599093    3.494338  ]\n",
      " [ 1.0490185  -1.3910714 ]\n",
      " [-3.70216     3.537061  ]\n",
      " [-3.0258543   2.9515426 ]\n",
      " [ 2.326444   -2.7566907 ]\n",
      " [-2.689628    2.374509  ]\n",
      " [-3.653126    3.5004687 ]\n",
      " [ 1.4293942  -1.8623133 ]\n",
      " [-2.6193485   2.5834854 ]]\n",
      "[1 0 0 1 0 1 0 1 1 1 1 0 0 1 1 1 1 0 1 0 0 1 0 1 1 1 0 1 1 1 0 1 1 1 1 0 0\n",
      " 0 1 1 0 1 0 0 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1\n",
      " 1 1 0 1 1 1 0 1 1 0 1 0 1 0 1 1 0 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1 1 0 0 1 1\n",
      " 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 0 1 0 1 1 0 0 1 0 1 0 0 1 0 0 1 1\n",
      " 1 1 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 0 1 1 0 1 1 0 0 1 1 0\n",
      " 1 0 1 0 1 1 0 1 1 0 1 1 0 1 1 1 0 1 1 1 0 1 1 1 0 0 1 1 0 1 1 1 1 0 1 1 1\n",
      " 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 1 0 1 1 1 1 1 0 1 1 1 0 1 0 1 0 1 1 1\n",
      " 0 1 0 1 1 0 1 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 0\n",
      " 0 0 1 1 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 0 1 1 0 0 0 0 0 1 0 1 0 1 1 1 1 1 0\n",
      " 1 1 1 1 0 0 1 1 1 0 0 1 1 1 1 0 1 0 1 0 1 0 0 1 1 1 1 0 1 1 0 1 1 0 1 0 0\n",
      " 1 1 1 1 0 0 0 0 1 1 1 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 0\n",
      " 1]\n"
     ]
    }
   ],
   "source": [
    "predictions = trainer.predict(tokenized_datasets[\"validation\"]) # Predict method allows us to get the predictions of the model based on the entire dataset\n",
    "print(predictions.predictions.shape, predictions.label_ids.shape)\n",
    "print(predictions.predictions)\n",
    "print(predictions.label_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a17a290a-4374-4b97-8fce-76287a3db1fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 1 0 1 1 1 1 1 1 0 0 1 1 0 1 0 1 0 0 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 0\n",
      " 0 0 1 0 1 0 0 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 0 0 1 1\n",
      " 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 0 1 0 1 1 0 0 1 1 1 1 0 1 0 1 1 1\n",
      " 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 0 1 1 0 1 1 0 0 1 1 1\n",
      " 1 0 1 0 1 1 0 0 1 1 1 1 0 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 0 1 1 1 1 0 1 0 1\n",
      " 1 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1\n",
      " 0 1 1 1 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 0 0 0 1 1 1 0\n",
      " 0 1 1 1 1 1 1 0 1 1 0 1 0 0 1 1 1 0 1 0 1 1 0 0 0 0 0 0 0 1 0 1 1 1 1 1 1\n",
      " 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0\n",
      " 1 1 1 1 0 0 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 0 1 1 0\n",
      " 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8553921568627451, 'f1': 0.8987993138936535}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from datasets import load_metric\n",
    "\n",
    "metric = load_metric(\"glue\", \"mrpc\")\n",
    "preds = np.argmax(predictions.predictions, axis=-1) # Max logit is taken to predict the which class was predicted\n",
    "print(preds)\n",
    "metric.compute(predictions=preds, references=predictions.label_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd3a9b38-850a-4d76-ad0c-c498b9761cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = load_metric(\"glue\", \"mrpc\")\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9fb948b7-02af-4e9b-b171-89b7c17b71ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1377' max='1377' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1377/1377 01:14, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.469034</td>\n",
       "      <td>0.808824</td>\n",
       "      <td>0.861210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.558100</td>\n",
       "      <td>0.623080</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.867089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.360600</td>\n",
       "      <td>0.617194</td>\n",
       "      <td>0.857843</td>\n",
       "      <td>0.900685</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1377, training_loss=0.39661268401855826, metrics={'train_runtime': 75.3841, 'train_samples_per_second': 145.972, 'train_steps_per_second': 18.266, 'total_flos': 419378466692640.0, 'train_loss': 0.39661268401855826, 'epoch': 3.0})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\"test-trainer\", evaluation_strategy=\"epoch\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b01a183-56e4-47b8-8b05-bdb77680f6eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
